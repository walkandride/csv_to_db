{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of checkin_checkout_history_updated.csv:\n",
      "          user_id  gym_id         checkin_time        checkout_time  \\\n",
      "0       user_3291   gym_6  2023-09-10 15:55:00  2023-09-10 16:34:00   \n",
      "1       user_1944   gym_2  2023-04-13 20:07:00  2023-04-13 22:43:00   \n",
      "2        user_958   gym_7  2023-06-10 12:24:00  2023-06-10 13:49:00   \n",
      "3        user_811   gym_2  2023-05-23 17:11:00  2023-05-23 20:01:00   \n",
      "4       user_4923  gym_10  2023-02-21 06:20:00  2023-02-21 08:02:00   \n",
      "...           ...     ...                  ...                  ...   \n",
      "299995  user_3995   gym_3  2023-08-06 17:25:00  2023-08-06 18:09:00   \n",
      "299996   user_206   gym_9  2023-06-27 13:14:00  2023-06-27 16:04:00   \n",
      "299997  user_4983   gym_4  2023-04-08 14:41:00  2023-04-08 15:54:00   \n",
      "299998  user_1028  gym_10  2023-03-05 06:07:00  2023-03-05 07:04:00   \n",
      "299999  user_3314   gym_4  2023-01-05 08:58:00  2023-01-05 09:48:00   \n",
      "\n",
      "         workout_type  calories_burned  \n",
      "0       Weightlifting              462  \n",
      "1                Yoga             1278  \n",
      "2              Cardio              858  \n",
      "3                Yoga             1134  \n",
      "4       Weightlifting             1049  \n",
      "...               ...              ...  \n",
      "299995        Pilates              288  \n",
      "299996  Weightlifting             1935  \n",
      "299997         Cardio             1312  \n",
      "299998         Cardio              787  \n",
      "299999           Yoga              512  \n",
      "\n",
      "[300000 rows x 6 columns]\n",
      "\n",
      "\n",
      "Contents of gym_locations_data.csv:\n",
      "   gym_id      location  gym_type  \\\n",
      "0   gym_1      New York   Premium   \n",
      "1   gym_2   Los Angeles    Budget   \n",
      "2   gym_3       Chicago    Budget   \n",
      "3   gym_4       Houston   Premium   \n",
      "4   gym_5       Phoenix  Standard   \n",
      "5   gym_6  Philadelphia    Budget   \n",
      "6   gym_7   San Antonio   Premium   \n",
      "7   gym_8     San Diego  Standard   \n",
      "8   gym_9        Dallas   Premium   \n",
      "9  gym_10      San Jose   Premium   \n",
      "\n",
      "                                       facilities  \n",
      "0  Climbing Wall, Swimming Pool, Basketball Court  \n",
      "1              Climbing Wall, Yoga Classes, Sauna  \n",
      "2             Sauna, Climbing Wall, Swimming Pool  \n",
      "3  Climbing Wall, Basketball Court, Swimming Pool  \n",
      "4       Basketball Court, CrossFit, Swimming Pool  \n",
      "5             Swimming Pool, Climbing Wall, Sauna  \n",
      "6          Sauna, Basketball Court, Swimming Pool  \n",
      "7               Basketball Court, Sauna, CrossFit  \n",
      "8                   Sauna, CrossFit, Yoga Classes  \n",
      "9                  Swimming Pool, Sauna, CrossFit  \n",
      "\n",
      "\n",
      "Contents of subscription_plans.csv:\n",
      "  subscription_plan  price_per_month  \\\n",
      "0             Basic            19.99   \n",
      "1               Pro            49.99   \n",
      "2           Student             9.99   \n",
      "\n",
      "                                            features  \n",
      "0  Access to basic gym facilities, Limited class ...  \n",
      "1  Access to all facilities, Unlimited class acce...  \n",
      "2  Access to basic facilities, Limited class acce...  \n",
      "\n",
      "\n",
      "Contents of users_data.csv:\n",
      "        user_id first_name last_name  age      gender   birthdate  \\\n",
      "0        user_1      Chris    Wilson   56      Female  2000-02-29   \n",
      "1        user_2    Michael    Miller   46  Non-binary  1978-12-22   \n",
      "2        user_3     Daniel     Smith   32      Female  1962-08-30   \n",
      "3        user_4      David     Smith   60        Male  2003-12-05   \n",
      "4        user_5      Chris     Jones   25      Female  2004-08-25   \n",
      "...         ...        ...       ...  ...         ...         ...   \n",
      "4995  user_4996      Sarah  Williams   33        Male  1958-01-13   \n",
      "4996  user_4997      Linda     Brown   22        Male  1974-02-20   \n",
      "4997  user_4998      Emily    Miller   38  Non-binary  1978-03-29   \n",
      "4998  user_4999     Robert    Garcia   27        Male  2002-02-01   \n",
      "4999  user_5000      Chris     Smith   36        Male  1959-11-21   \n",
      "\n",
      "     sign_up_date user_location subscription_plan  \n",
      "0      2023-02-06        Denver             Basic  \n",
      "1      2023-08-08       Orlando               Pro  \n",
      "2      2021-01-11       Orlando             Basic  \n",
      "3      2023-08-07        Denver               Pro  \n",
      "4      2021-01-08        Denver             Basic  \n",
      "...           ...           ...               ...  \n",
      "4995   2021-08-08     Las Vegas             Basic  \n",
      "4996   2023-01-22        Austin           Student  \n",
      "4997   2021-04-16       Atlanta               Pro  \n",
      "4998   2022-07-02        Denver               Pro  \n",
      "4999   2022-02-20       Seattle           Student  \n",
      "\n",
      "[5000 rows x 9 columns]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the directory containing the CSV files\n",
    "directory = 'data'\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        # Print the DataFrame\n",
    "        print(f'Contents of {filename}:')\n",
    "        print(df)\n",
    "        print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized (OLTP) schema\n",
    "Designed to reduce redundancy and ensure data integrity by organizing the data into multiple related tables.\n",
    "\n",
    "1. **Users**\n",
    "   - **user_id_pk** (PK)\n",
    "   - **fk_subscription_plan_id** (FK)\n",
    "   - **first_name**\n",
    "   - **last_name**\n",
    "   - **age**\n",
    "   - **gender**\n",
    "   - **birthdate**\n",
    "   - **sign_up_date**\n",
    "   - **user_location**\n",
    "\n",
    "2. **Gyms**\n",
    "   - **gym_id_pk** (PK)\n",
    "   - **location**\n",
    "   - **gym_type**\n",
    "   - **facilities**\n",
    "\n",
    "3. **Subscription Plans**\n",
    "   - **subscription_plan_id_pk** (PK)\n",
    "   - **plan_name**\n",
    "   - **price_per_month**\n",
    "   - **features**\n",
    "\n",
    "4. **Check-ins**\n",
    "   - **checkin_id_pk** (PK)\n",
    "   - **fk_user_id** (FK)\n",
    "   - **fk_gym_id** (FK)\n",
    "   - **checkin_time**\n",
    "   - **checkout_time**\n",
    "   - **workout_type**\n",
    "   - **calories_burned**\n",
    "\n",
    "#### Relationships\n",
    "- **Users** to **Subscription Plans**:  One-to-Many\n",
    "- **Check-ins** to **Users**:  Many-to-One\n",
    "- **Check-ins** to **Gyms**:  Many-to-One\n",
    "\n",
    "#### Schema Definition\n",
    "\n",
    "```sql\n",
    "CREATE TABLE users (\n",
    "    user_id_pk INT PRIMARY KEY,\n",
    "    fk_subscription_plan_id INT,\n",
    "    first_name VARCHAR(50),\n",
    "    last_name VARCHAR(50),\n",
    "    age INT,\n",
    "    gender VARCHAR(10),\n",
    "    birthdate DATE,\n",
    "    sign_up_date DATE,\n",
    "    user_location VARCHAR(100),\n",
    "    FOREIGN KEY (fk_subscription_plan_id) REFERENCES subscription_plans(subscription_plan_id_pk)\n",
    ");\n",
    "\n",
    "CREATE TABLE gyms (\n",
    "    gym_id_pk INT PRIMARY KEY,\n",
    "    location VARCHAR(100),\n",
    "    gym_type VARCHAR(50),\n",
    "    facilities TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE subscription_plans (\n",
    "    subscription_plan_id_pk INT PRIMARY KEY,\n",
    "    plan_name VARCHAR(50),\n",
    "    price_per_month DECIMAL(10, 2),\n",
    "    features TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE checkins (\n",
    "    checkin_id_pk SERIAL PRIMARY KEY,\n",
    "    fk_user_id INT,\n",
    "    fk_gym_id INT,\n",
    "    checkin_time TIMESTAMP,\n",
    "    checkout_time TIMESTAMP,\n",
    "    workout_type VARCHAR(50),\n",
    "    calories_burned INT,\n",
    "    FOREIGN KEY (fk_user_id) REFERENCES users(user_id_pk),\n",
    "    FOREIGN KEY (fk_gym_id) REFERENCES gyms(gym_id_pk)\n",
    ");\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Star schema\n",
    "Simplifies complex queries with a central fact table connected to dimension tables.\n",
    "\n",
    "**Fact Table: Check-in/Checkout History**\n",
    "- **fk_user_id** (FK)\n",
    "- **fk_gym_id** (FK)\n",
    "- **checkin_time**\n",
    "- **checkout_time**\n",
    "- **workout_type**\n",
    "- **calories_burned**\n",
    "\n",
    "**Dimension Tables:**\n",
    "\n",
    "1. **Users**\n",
    "   - **user_id_pk** (PK)\n",
    "   - **first_name**\n",
    "   - **last_name**\n",
    "   - **age**\n",
    "   - **gender**\n",
    "   - **birthdate**\n",
    "   - **sign_up_date**\n",
    "   - **user_location**\n",
    "   - **subscription_plan_name**\n",
    "\n",
    "2. **Gyms**\n",
    "   - **gym_id_pk** (PK)\n",
    "   - **location**\n",
    "   - **gym_type**\n",
    "   - **facilities**\n",
    "\n",
    "3. **Subscription Plans**\n",
    "   - **subscription_plan_pk** (PK)\n",
    "   - **plan_name**\n",
    "   - **price_per_month**\n",
    "   - **features**\n",
    "\n",
    "#### Schema definition\n",
    "\n",
    "```sql\n",
    "CREATE TABLE users (\n",
    "    user_id_pk INT PRIMARY KEY,\n",
    "    subscription_plan_id INT,\n",
    "    first_name VARCHAR(50),\n",
    "    last_name VARCHAR(50),\n",
    "    age INT,\n",
    "    gender VARCHAR(10),\n",
    "    birthdate DATE,\n",
    "    sign_up_date DATE,\n",
    "    user_location VARCHAR(100)\n",
    ");\n",
    "\n",
    "CREATE TABLE gyms (\n",
    "    gym_id_pk INT PRIMARY KEY,\n",
    "    location VARCHAR(100),\n",
    "    gym_type VARCHAR(50),\n",
    "    facilities TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE subscription_plans (\n",
    "    subscription_plan_id_pk INT PRIMARY KEY,\n",
    "    plan_name VARCHAR(50),\n",
    "    price_per_month DECIMAL(10, 2),\n",
    "    features TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE checkins (\n",
    "    fk_user_id INT,\n",
    "    fk_gym_id INT,\n",
    "    checkin_time TIMESTAMP,\n",
    "    checkout_time TIMESTAMP,\n",
    "    workout_type VARCHAR(50),\n",
    "    calories_burned INT\n",
    ");\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snowflake schema\n",
    "Normalized form of the star schema, reducing redundancy.\n",
    "\n",
    "1. **Fact Table**: Central table containing quantitative data.\n",
    "2. **Dimension Tables**: Surrounding tables containing descriptive attributes, further normalized into sub-dimension tables.\n",
    "\n",
    "**Fact Table: Check-ins**\n",
    "- **checkin_id_pk** (PK)\n",
    "- **fk_user_id** (FK)\n",
    "- **fk_gym_id** (FK)\n",
    "- **checkin_time**\n",
    "- **checkout_time**\n",
    "- **workout_type**\n",
    "- **calories_burned**\n",
    "\n",
    "**Dimension Tables**\n",
    "\n",
    "1. **Users**\n",
    "   - **user_id_pk** (PK)\n",
    "   - **fk_subscription_plan_id** (FK)\n",
    "   - **first_name**\n",
    "   - **last_name**\n",
    "   - **age**\n",
    "   - **gender**\n",
    "   - **birthdate**\n",
    "   - **sign_up_date**\n",
    "   - **user_location**\n",
    "\n",
    "2. **Gyms**\n",
    "   - **gym_id_pk** (PK)\n",
    "   - **fk_location_id** (FK)\n",
    "   - **gym_type**\n",
    "   - **facilities**\n",
    "\n",
    "3. **Subscription Plans**\n",
    "   - **subscription_plan_id** (PK)\n",
    "   - **plan_name**\n",
    "   - **price_per_month**\n",
    "   - **features**\n",
    "\n",
    "**Sub-Dimension Tables**\n",
    "\n",
    "1. **Locations**\n",
    "   - **location_id_pk** (PK)\n",
    "   - **location_name**\n",
    "   - **address**\n",
    "   - **city**\n",
    "   - **state**\n",
    "   - **zip_code**\n",
    "\n",
    "### Relationships\n",
    "\n",
    "- **Users** to **Subscription Plans**: One-to-Many\n",
    "- **Gyms** to **Locations**: Many-to-One\n",
    "- **Check-ins** to **Users**: Many-to-One\n",
    "- **Check-ins** to **Gyms**: Many-to-One\n",
    "\n",
    "#### Schema definition\n",
    "\n",
    "```sql\n",
    "CREATE TABLE users (\n",
    "    user_id_pk INT PRIMARY KEY,\n",
    "    fk_subscription_plan_id INT,\n",
    "    first_name VARCHAR(50),\n",
    "    last_name VARCHAR(50),\n",
    "    age INT,\n",
    "    gender VARCHAR(10),\n",
    "    birthdate DATE,\n",
    "    sign_up_date DATE,\n",
    "    user_location VARCHAR(100),\n",
    "    FOREIGN KEY (fk_subscription_plan_id) REFERENCES subscription_plans(subscription_plan_id_pk)\n",
    ");\n",
    "\n",
    "CREATE TABLE gyms (\n",
    "    gym_id_pk INT PRIMARY KEY,\n",
    "    location_id VARCHAR(100),\n",
    "    gym_type VARCHAR(50),\n",
    "    facilities TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE subscription_plans (\n",
    "    subscription_plan_id_pk INT PRIMARY KEY,\n",
    "    plan_name VARCHAR(50),\n",
    "    price_per_month DECIMAL(10, 2),\n",
    "    features TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE checkins (\n",
    "    checkin_id_pk SERIAL PRIMARY KEY,\n",
    "    fk_user_id INT,\n",
    "    fk_gym_id INT,\n",
    "    checkin_time TIMESTAMP,\n",
    "    checkout_time TIMESTAMP,\n",
    "    workout_type VARCHAR(50),\n",
    "    calories_burned INT,\n",
    "    FOREIGN KEY (fk_user_id) REFERENCES users(user_id_pk),\n",
    "    FOREIGN KEY (fk_gym_id) REFERENCES gyms(gym_id_pk)\n",
    ");\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postgres database build script.\n",
    "From **psql**, execute the created *db_build.sql* file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Postgres database build script.\n",
    "\n",
    "db_build_script = r\"\"\"\n",
    "SELECT pg_terminate_backend(pid)\n",
    "FROM pg_stat_activity\n",
    "WHERE datname = 'csv_oltp';\n",
    "\n",
    "DROP DATABASE IF EXISTS csv_oltp;\n",
    "CREATE DATABASE csv_oltp;\n",
    "\\connect csv_oltp;\n",
    "CREATE SCHEMA schema_oltp;\n",
    "\n",
    "CREATE TABLE schema_oltp.gyms (\n",
    "    gym_id_pk INT PRIMARY KEY,\n",
    "    location VARCHAR(100),\n",
    "    gym_type VARCHAR(50),\n",
    "    facilities TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE schema_oltp.subscription_plans (\n",
    "    subscription_plan_id_pk INT PRIMARY KEY,\n",
    "    plan_name VARCHAR(50),\n",
    "    price_per_month DECIMAL(10, 2),\n",
    "    features TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE schema_oltp.users (\n",
    "    user_id_pk INT PRIMARY KEY,\n",
    "    fk_subscription_plan_id INT,\n",
    "    first_name VARCHAR(50),\n",
    "    last_name VARCHAR(50),\n",
    "    age INT,\n",
    "    gender VARCHAR(10),\n",
    "    birthdate DATE,\n",
    "    sign_up_date DATE,\n",
    "    user_location VARCHAR(100),\n",
    "    FOREIGN KEY (fk_subscription_plan_id) REFERENCES schema_oltp.subscription_plans(subscription_plan_id_pk)\n",
    ");\n",
    "\n",
    "CREATE TABLE schema_oltp.checkins (\n",
    "    checkin_id_pk SERIAL PRIMARY KEY,\n",
    "    fk_user_id INT,\n",
    "    fk_gym_id INT,\n",
    "    checkin_time TIMESTAMP,\n",
    "    checkout_time TIMESTAMP,\n",
    "    workout_type VARCHAR(50),\n",
    "    calories_burned INT,\n",
    "    FOREIGN KEY (fk_user_id) REFERENCES schema_oltp.users(user_id_pk),\n",
    "    FOREIGN KEY (fk_gym_id) REFERENCES schema_oltp.gyms(gym_id_pk)\n",
    ");\n",
    "\n",
    "\n",
    "SELECT pg_terminate_backend(pid)\n",
    "FROM pg_stat_activity\n",
    "WHERE datname = 'csv_star';\n",
    "\n",
    "DROP DATABASE IF EXISTS csv_star;\n",
    "CREATE DATABASE csv_star;\n",
    "\\connect csv_star;\n",
    "CREATE SCHEMA schema_star;\n",
    "\n",
    "CREATE TABLE schema_star.users (\n",
    "    user_id_pk INT PRIMARY KEY,\n",
    "    subscription_plan_name VARCHAR(50),\n",
    "    first_name VARCHAR(50),\n",
    "    last_name VARCHAR(50),\n",
    "    age INT,\n",
    "    gender VARCHAR(10),\n",
    "    birthdate DATE,\n",
    "    sign_up_date DATE,\n",
    "    user_location VARCHAR(100)\n",
    ");\n",
    "\n",
    "CREATE TABLE schema_star.gyms (\n",
    "    gym_id_pk INT PRIMARY KEY,\n",
    "    location VARCHAR(100),\n",
    "    gym_type VARCHAR(50),\n",
    "    facilities TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE schema_star.subscription_plans (\n",
    "    subscription_plan_id_pk INT PRIMARY KEY,\n",
    "    plan_name VARCHAR(50),\n",
    "    price_per_month DECIMAL(10, 2),\n",
    "    features TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE schema_star.checkins (\n",
    "    fk_user_id INT,\n",
    "    fk_gym_id INT,\n",
    "    checkin_time TIMESTAMP,\n",
    "    checkout_time TIMESTAMP,\n",
    "    workout_type VARCHAR(50),\n",
    "    calories_burned INT\n",
    ");\n",
    "\n",
    "\n",
    "SELECT pg_terminate_backend(pid)\n",
    "FROM pg_stat_activity\n",
    "WHERE datname = 'csv_snow';\n",
    "\n",
    "DROP DATABASE IF EXISTS csv_snow;\n",
    "CREATE DATABASE csv_snow;\n",
    "\\connect csv_snow;\n",
    "CREATE SCHEMA schema_snow;\n",
    "\n",
    "CREATE TABLE schema_snow.subscription_plans (\n",
    "    subscription_plan_id_pk INT PRIMARY KEY,\n",
    "    plan_name VARCHAR(50),\n",
    "    price_per_month DECIMAL(10, 2),\n",
    "    features TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE schema_snow.users (\n",
    "    user_id_pk INT PRIMARY KEY,\n",
    "    fk_subscription_plan_id INT,\n",
    "    first_name VARCHAR(50),\n",
    "    last_name VARCHAR(50),\n",
    "    age INT,\n",
    "    gender VARCHAR(10),\n",
    "    birthdate DATE,\n",
    "    sign_up_date DATE,\n",
    "    user_location VARCHAR(100),\n",
    "    FOREIGN KEY (fk_subscription_plan_id) REFERENCES schema_snow.subscription_plans(subscription_plan_id_pk)\n",
    ");\n",
    "\n",
    "CREATE TABLE schema_snow.gyms (\n",
    "    gym_id_pk INT PRIMARY KEY,\n",
    "    location VARCHAR(100),\n",
    "    gym_type VARCHAR(50),\n",
    "    facilities TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE schema_snow.checkins (\n",
    "    checkin_id_pk SERIAL PRIMARY KEY,\n",
    "    fk_user_id INT,\n",
    "    fk_gym_id INT,\n",
    "    checkin_time TIMESTAMP,\n",
    "    checkout_time TIMESTAMP,\n",
    "    workout_type VARCHAR(50),\n",
    "    calories_burned INT,\n",
    "    FOREIGN KEY (fk_user_id) REFERENCES schema_snow.users(user_id_pk),\n",
    "    FOREIGN KEY (fk_gym_id) REFERENCES schema_snow.gyms(gym_id_pk)\n",
    ");\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with open(\"db_build.sql\", \"w\") as file:\n",
    "    file.write(db_build_script)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A database build file, **db_build.sql**, was created.  Enter **psql**, then execute the file by entering:\n",
    "\n",
    "```sql\n",
    "\\i /path/to/db_build.sql\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wait for a key press\n",
    "input(\"Build DB then press Enter to continue...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define database connection parameters\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"abcd1234\"\n",
    "DB_HOST = \"192.168.50.75\"\n",
    "DB_PORT = \"5432\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "def get_connection(db):\n",
    "    # Database connection parameters\n",
    "    conn = psycopg2.connect(       \n",
    "        dbname=db,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD,\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT\n",
    "    )\n",
    "\n",
    "    return conn, conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_count(db, table_name):\n",
    "    conn, cur = get_connection(db)\n",
    "\n",
    "    cur.execute(f\"SELECT COUNT(*) FROM {table_name};\")\n",
    "    count = cur.fetchone()[0]\n",
    "\n",
    "    print(f\"{table_name} row count: {count}\")\n",
    "\n",
    "    # Close connection\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_rows_sql(table_name, n=3):\n",
    "    sql = f\"SELECT * FROM {table_name} ORDER BY RANDOM() LIMIT {n};\"\n",
    "    return sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "\n",
    "def display_results(engine, sql):\n",
    "    with engine.connect() as conn:\n",
    "        print(conn.execute(text(sql)).fetchall())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "def get_engine(db):\n",
    "    # Database connection details\n",
    "    username = DB_USER\n",
    "    password = DB_PASSWORD\n",
    "    host = DB_HOST\n",
    "    port = DB_PORT\n",
    "    database = db\n",
    "\n",
    "    # Create a SQLAlchemy engine\n",
    "    return create_engine(f'postgresql://{username}:{password}@{host}:{port}/{database}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup OLTP Schema\n",
    "Since this is the first data load for the tables, confirm that they are currently unpopulated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn, cur = get_connection('csv_oltp')\n",
    "\n",
    "# List of DELETE statements\n",
    "delete_statements = [\n",
    "    \"DELETE FROM schema_oltp.checkins CASCADE;\",\n",
    "    \"DELETE FROM schema_oltp.users CASCADE;\",\n",
    "    \"DELETE FROM schema_oltp.gyms CASCADE;\",\n",
    "    \"DELETE FROM schema_oltp.subscription_plans CASCADE;\",\n",
    "]\n",
    "\n",
    "# Execute each DELETE statement\n",
    "for statement in delete_statements:\n",
    "    cur.execute(statement)\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load OTLP schema\n",
    "- gyms\n",
    "    - The index value is prefixed with \"gym_\", remove it.\n",
    "- subscription_plans\n",
    "- users\n",
    "    - The index value is prefixed with \"user_\", remove it.\n",
    "- checkins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load gym table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 'Chicago', 'Budget', 'Sauna, Climbing Wall, Swimming Pool'), (7, 'San Antonio', 'Premium', 'Sauna, Basketball Court, Swimming Pool'), (1, 'New York', 'Premium', 'Climbing Wall, Swimming Pool, Basketball Court')]\n",
      "schema_oltp.gyms row count: 10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "# read file\n",
    "file_path = 'data/gym_locations_data.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "# extract gym_id_pk, the index value\n",
    "df['gym_id_pk'] = df['gym_id'].str.extract(r'(\\d+)').astype(int)\n",
    "# reorder columns to match table\n",
    "df = df[['gym_id_pk', 'location',  'gym_type', 'facilities']]\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine = get_engine('csv_oltp')\n",
    "\n",
    "# Insert DataFrame into PostgreSQL table\n",
    "df.to_sql('gyms', engine, schema='schema_oltp', if_exists='append', index=False)\n",
    "display_results(engine, get_random_rows_sql(\"schema_oltp.gyms\"))\n",
    "display_count(\"csv_oltp\", \"schema_oltp.gyms\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load subscription_plans table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 'Pro', Decimal('49.99'), 'Access to all facilities, Unlimited class access, 5 guest passes per month, Free personal trainer session'), (1, 'Basic', Decimal('19.99'), 'Access to basic gym facilities, Limited class access, 1 guest pass per month'), (3, 'Student', Decimal('9.99'), 'Access to basic facilities, Limited class access, 1 guest pass per month, Discounted for students')]\n",
      "schema_oltp.subscription_plans row count: 3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "# read file\n",
    "file_path = 'data/subscription_plans.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'index': 'subscription_plan_id_pk'}, inplace=True)\n",
    "df['subscription_plan_id_pk'] = df.index + 1\n",
    "df.rename(columns={'subscription_plan' : 'plan_name'}, inplace=True)\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine = get_engine('csv_oltp')\n",
    "\n",
    "# Insert DataFrame into PostgreSQL table\n",
    "df.to_sql('subscription_plans', engine, schema='schema_oltp', if_exists='append', index=False)\n",
    "display_results(engine, get_random_rows_sql(\"schema_oltp.subscription_plans\"))\n",
    "display_count(\"csv_oltp\", \"schema_oltp.subscription_plans\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load users table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4557, 1, 'Laura', 'Jones', 60, 'Female', datetime.date(1979, 12, 27), datetime.date(2023, 3, 4), 'Orlando'), (4455, 2, 'Jane', 'Brown', 35, 'Male', datetime.date(1972, 10, 19), datetime.date(2022, 8, 6), 'Denver'), (4964, 3, 'Michael', 'Davis', 29, 'Female', datetime.date(1992, 4, 13), datetime.date(2022, 11, 1), 'San Francisco')]\n",
      "schema_oltp.users row count: 5000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "# read file\n",
    "file_path = 'data/users_data.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "# extract user_id_pk, the index value\n",
    "df['user_id_pk'] = df['user_id'].str.extract(r'(\\d+)').astype(int)\n",
    "plan_mapping = {'Basic': 1, 'Pro': 2, 'Student': 3}\n",
    "df['fk_subscription_plan_id'] = df['subscription_plan'].map(plan_mapping)\n",
    "\n",
    "# reorder columns to match table\n",
    "df = df[['user_id_pk', 'fk_subscription_plan_id',  'first_name', 'last_name', 'age', 'gender', 'birthdate', 'sign_up_date', 'user_location']]\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine = get_engine('csv_oltp')\n",
    "\n",
    "# Insert DataFrame into PostgreSQL table\n",
    "df.to_sql('users', engine, schema='schema_oltp', if_exists='append', index=False)\n",
    "display_results(engine, get_random_rows_sql(\"schema_oltp.users\"))\n",
    "display_count(\"csv_oltp\", \"schema_oltp.users\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load checkins table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(357770, 3392, 6, datetime.datetime(2023, 5, 8, 6, 46), datetime.datetime(2023, 5, 8, 7, 21), 'Yoga', 1429), (352724, 2921, 5, datetime.datetime(2023, 6, 22, 9, 46), datetime.datetime(2023, 6, 22, 12, 25), 'Pilates', 1624), (359617, 3917, 3, datetime.datetime(2023, 8, 30, 12, 0), datetime.datetime(2023, 8, 30, 12, 36), 'Pilates', 1926)]\n",
      "schema_oltp.checkins row count: 300000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "# read file\n",
    "file_path = 'data/checkin_checkout_history_updated.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "# extract user_id_pk, the index value\n",
    "df['fk_user_id'] = df['user_id'].str.extract(r'(\\d+)').astype(int)\n",
    "df['fk_gym_id'] = df['gym_id'].str.extract(r'(\\d+)').astype(int)\n",
    "\n",
    "# reorder columns to match table\n",
    "df = df[['fk_user_id', 'fk_gym_id',  'checkin_time', 'checkout_time', 'workout_type', 'calories_burned']]\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine = get_engine('csv_oltp')\n",
    "\n",
    "# Insert DataFrame into PostgreSQL table\n",
    "df.to_sql('checkins', engine, schema='schema_oltp', if_exists='append', index=False)\n",
    "display_results(engine, get_random_rows_sql(\"schema_oltp.checkins\"))\n",
    "display_count(\"csv_oltp\", \"schema_oltp.checkins\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the option to replicate the method used for OLTP schemas by employing Python scripts for each OLAP table. However, considering the OLTP tables are already in place, a direct database-to-database transfer would be more efficient and faster. Therefore, crafting a set of SQL scripts to populate the OLAP tables would be the preferable approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup OLAP Star Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn, cur = get_connection('csv_star')\n",
    "\n",
    "# List of DELETE statements\n",
    "delete_statements = [\n",
    "    \"DELETE FROM schema_star.checkins;\",\n",
    "    \"DELETE FROM schema_star.users;\",\n",
    "    \"DELETE FROM schema_star.gyms;\",\n",
    "    \"DELETE FROM schema_star.subscription_plans;\",\n",
    "]\n",
    "\n",
    "# Execute each DELETE statement\n",
    "for statement in delete_statements:\n",
    "    cur.execute(statement)\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load OLAP Star schema\n",
    "- users\n",
    "- gyms\n",
    "- subscription_plans\n",
    "- checkins\n",
    "\n",
    "In the OLAP Star schema, the absence of foreign key relationships means that the sequence of tables is inconsequential. This design allows for a more flexible approach to data analysis, as the structure does not impose a hierarchy on the tables, enabling various ways to query and manage the data without concern for table arrangement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLAP Star SQL statements \n",
    "# These commands are designed to retrieve data from OLTP databases as \n",
    "# a preliminary step before populating the corresponding OLAP tables.\n",
    "\n",
    "users_load_star_sql = \"\"\"\n",
    "SELECT user_id_pk\n",
    "       , sp.plan_name AS subscription_plan_name\n",
    "       , first_name\n",
    "       , last_name\n",
    "       , age\n",
    "       , gender\n",
    "       , birthdate\n",
    "       , sign_up_date\n",
    "       , user_location\n",
    "FROM schema_oltp.users u\n",
    "     , schema_oltp.subscription_plans sp\n",
    "WHERE u.fk_subscription_plan_id = sp.subscription_plan_id_pk;\n",
    "\"\"\"\n",
    "\n",
    "gyms_load_star_sql = \"\"\"\n",
    "SELECT gym_id_pk\n",
    "\t   , location\n",
    "\t   , gym_type \n",
    "\t   , facilities\n",
    "FROM schema_oltp.gyms;\n",
    "\"\"\"\n",
    "\n",
    "subscription_plans_load_star_sql = \"\"\"\n",
    "SELECT subscription_plan_id_pk \n",
    "\t   , plan_name \n",
    "\t   , price_per_month \n",
    "\t   , features\n",
    "FROM schema_oltp.subscription_plans;\n",
    "\"\"\"\n",
    "\n",
    "checkins_star_load_sql = \"\"\"\n",
    "SELECT fk_user_id \n",
    "       , fk_gym_id \n",
    "       , checkin_time \n",
    "       , checkout_time \n",
    "       , workout_type \n",
    "       , calories_burned \n",
    "FROM schema_oltp.checkins;\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4175, 'Student', 'Daniel', 'Garcia', 52, 'Male', datetime.date(1959, 12, 19), datetime.date(2022, 4, 11), 'Boston'), (1686, 'Basic', 'Jessica', 'Moore', 49, 'Female', datetime.date(1978, 4, 13), datetime.date(2022, 7, 22), 'Seattle'), (546, 'Basic', 'Chris', 'Smith', 56, 'Non-binary', datetime.date(1966, 6, 22), datetime.date(2021, 8, 2), 'Austin')]\n",
      "schema_star.users row count: 5000\n",
      "[(7, 'San Antonio', 'Premium', 'Sauna, Basketball Court, Swimming Pool'), (2, 'Los Angeles', 'Budget', 'Climbing Wall, Yoga Classes, Sauna'), (9, 'Dallas', 'Premium', 'Sauna, CrossFit, Yoga Classes')]\n",
      "schema_star.gyms row count: 10\n",
      "[(1, 'Basic', Decimal('19.99'), 'Access to basic gym facilities, Limited class access, 1 guest pass per month'), (3, 'Student', Decimal('9.99'), 'Access to basic facilities, Limited class access, 1 guest pass per month, Discounted for students'), (2, 'Pro', Decimal('49.99'), 'Access to all facilities, Unlimited class access, 5 guest passes per month, Free personal trainer session')]\n",
      "schema_star.subscription_plans row count: 3\n",
      "[(13, 4, datetime.datetime(2023, 2, 17, 9, 30), datetime.datetime(2023, 2, 17, 11, 42), 'Pilates', 604), (3957, 1, datetime.datetime(2023, 9, 28, 10, 23), datetime.datetime(2023, 9, 28, 12, 37), 'Swimming', 876), (4061, 8, datetime.datetime(2023, 8, 6, 16, 42), datetime.datetime(2023, 8, 6, 19, 19), 'Yoga', 1314)]\n",
      "schema_star.checkins row count: 300000\n"
     ]
    }
   ],
   "source": [
    "engine_src = get_engine('csv_oltp')\n",
    "engine = get_engine('csv_star')\n",
    "\n",
    "# load users table\n",
    "df = pd.read_sql_query(users_load_star_sql, con=engine_src)\n",
    "df.to_sql('users', engine, schema='schema_star', if_exists='append', index=False)\n",
    "display_results(engine, get_random_rows_sql(\"schema_star.users\"))\n",
    "display_count(\"csv_star\", \"schema_star.users\")\n",
    "\n",
    "# load gyms table\n",
    "df = pd.read_sql_query(gyms_load_star_sql, con=engine_src)\n",
    "df.to_sql('gyms', engine, schema='schema_star', if_exists='append', index=False)\n",
    "display_results(engine, get_random_rows_sql(\"schema_star.gyms\"))\n",
    "display_count(\"csv_star\", \"schema_star.gyms\")\n",
    "\n",
    "# load subscription_plans table\n",
    "df = pd.read_sql_query(subscription_plans_load_star_sql, con=engine_src)\n",
    "df.to_sql('subscription_plans', engine, schema='schema_star', if_exists='append', index=False)\n",
    "display_results(engine, get_random_rows_sql(\"schema_star.subscription_plans\"))\n",
    "display_count(\"csv_star\", \"schema_star.subscription_plans\")\n",
    "\n",
    "# load checkins table\n",
    "df = pd.read_sql_query(checkins_star_load_sql, con=engine_src)\n",
    "df.to_sql('checkins', engine, schema='schema_star', if_exists='append', index=False)\n",
    "display_results(engine, get_random_rows_sql(\"schema_star.checkins\"))\n",
    "display_count(\"csv_star\", \"schema_star.checkins\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup OLAP Snow Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn, cur = get_connection('csv_snow')\n",
    "\n",
    "# List of DELETE statements\n",
    "delete_statements = [\n",
    "    \"DELETE FROM schema_snow.checkins;\",\n",
    "    \"DELETE FROM schema_snow.gyms;\",\n",
    "    \"DELETE FROM schema_snow.users;\",\n",
    "    \"DELETE FROM schema_snow.subscription_plans;\",\n",
    "]\n",
    "\n",
    "# Execute each DELETE statement\n",
    "for statement in delete_statements:\n",
    "    cur.execute(statement)\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load OLAP Snow schema\n",
    "- subscription_plans\n",
    "- users\n",
    "- gyms\n",
    "- checkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLAP Snow SQL Statements\n",
    "subscription_plans_load_snow_sql = \"\"\" \n",
    "SELECT subscription_plan_id_pk \n",
    "\t   , plan_name \n",
    "\t   , price_per_month \n",
    "\t   , features\n",
    "FROM schema_oltp.subscription_plans;\n",
    "\"\"\"\n",
    "\n",
    "users_load_snow_sql = \"\"\" \n",
    "SELECT user_id_pk \n",
    "       , fk_subscription_plan_id \n",
    "       , first_name \n",
    "       , last_name \n",
    "       , age \n",
    "       , gender \n",
    "       , birthdate \n",
    "       , sign_up_date \n",
    "       , user_location \n",
    "FROM schema_oltp.users;\n",
    "\"\"\"\n",
    "\n",
    "gyms_load_snow_sql = \"\"\" \n",
    "SELECT gym_id_pk\n",
    "\t   , location\n",
    "\t   , gym_type \n",
    "\t   , facilities\n",
    "FROM schema_oltp.gyms;\n",
    "\"\"\"\n",
    "\n",
    "checkins_load_snow_sql = \"\"\" \n",
    "SELECT fk_user_id \n",
    "       , fk_gym_id \n",
    "       , checkin_time \n",
    "       , checkout_time \n",
    "       , workout_type \n",
    "       , calories_burned \n",
    "FROM schema_oltp.checkins;\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'Basic', Decimal('19.99'), 'Access to basic gym facilities, Limited class access, 1 guest pass per month'), (2, 'Pro', Decimal('49.99'), 'Access to all facilities, Unlimited class access, 5 guest passes per month, Free personal trainer session'), (3, 'Student', Decimal('9.99'), 'Access to basic facilities, Limited class access, 1 guest pass per month, Discounted for students')]\n",
      "schema_snow.subscription_plans row count: 3\n",
      "[(4075, 2, 'John', 'Johnson', 47, 'Female', datetime.date(1997, 12, 27), datetime.date(2021, 11, 6), 'Orlando'), (3425, 1, 'Chris', 'Moore', 37, 'Male', datetime.date(1969, 9, 21), datetime.date(2021, 11, 4), 'San Francisco'), (3141, 3, 'Jessica', 'Wilson', 26, 'Female', datetime.date(1988, 6, 29), datetime.date(2022, 5, 9), 'San Francisco')]\n",
      "schema_snow.users row count: 5000\n",
      "[(9, 'Dallas', 'Premium', 'Sauna, CrossFit, Yoga Classes'), (5, 'Phoenix', 'Standard', 'Basketball Court, CrossFit, Swimming Pool'), (6, 'Philadelphia', 'Budget', 'Swimming Pool, Climbing Wall, Sauna')]\n",
      "schema_snow.gyms row count: 10\n",
      "[(500577, 2973, 10, datetime.datetime(2023, 8, 22, 17, 47), datetime.datetime(2023, 8, 22, 20, 12), 'Weightlifting', 1048), (371768, 4650, 2, datetime.datetime(2023, 7, 14, 17, 11), datetime.datetime(2023, 7, 14, 18, 40), 'Weightlifting', 703), (459343, 2586, 10, datetime.datetime(2023, 6, 27, 16, 52), datetime.datetime(2023, 6, 27, 17, 30), 'Weightlifting', 351)]\n",
      "schema_snow.checkins row count: 300000\n"
     ]
    }
   ],
   "source": [
    "engine_src = get_engine('csv_oltp')\n",
    "engine = get_engine('csv_snow')\n",
    "\n",
    "# load subscription_plans table\n",
    "df = pd.read_sql_query(subscription_plans_load_snow_sql, con=engine_src)\n",
    "df.to_sql('subscription_plans', engine, schema='schema_snow', if_exists='append', index=False)\n",
    "display_results(engine, get_random_rows_sql(\"schema_snow.subscription_plans\"))\n",
    "display_count(\"csv_snow\", \"schema_snow.subscription_plans\")\n",
    "\n",
    "# load users table\n",
    "df = pd.read_sql_query(users_load_snow_sql, con=engine_src)\n",
    "df.to_sql('users', engine, schema='schema_snow', if_exists='append', index=False)\n",
    "display_results(engine, get_random_rows_sql(\"schema_snow.users\"))\n",
    "display_count(\"csv_snow\", \"schema_snow.users\")\n",
    "\n",
    "# load gyms table\n",
    "df = pd.read_sql_query(gyms_load_snow_sql, con=engine_src)\n",
    "df.to_sql('gyms', engine, schema='schema_snow', if_exists='append', index=False)\n",
    "display_results(engine, get_random_rows_sql(\"schema_snow.gyms\"))\n",
    "display_count(\"csv_snow\", \"schema_snow.gyms\")\n",
    "\n",
    "# load checkins table\n",
    "df = pd.read_sql_query(checkins_load_snow_sql, con=engine_src)\n",
    "df.to_sql('checkins', engine, schema='schema_snow', if_exists='append', index=False)\n",
    "display_results(engine, get_random_rows_sql(\"schema_snow.checkins\"))\n",
    "display_count(\"csv_snow\", \"schema_snow.checkins\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The databases are now successfully populated with data and are ready for querying to extract insights. Given that the initial datasets used for filling the tables are relatively modest in size, the creation of database indexes is not a necessity at this stage. Nevertheless, it's important to note that as the volume of data increases, the efficiency of queries may diminish. Therefore, it's advisable to establish indexes on foreign key constraints as a standard practice to maintain query performance over time.\n",
    "\n",
    "```sql\n",
    "-- OLTP indexes\n",
    "CREATE INDEX checkins_idx01 ON schema_oltp.checkins(fk_user_id);\n",
    "CREATE INDEX checkins_idx02 ON schema_oltp.checkins(fk_gym_id);\n",
    "\n",
    "CREATE INDEX subscription_plans_idx01 ON schema_oltp.users(fk_subscription_plan_id);\n",
    "\n",
    "-- OLAP snowflake indexes\n",
    "CREATE INDEX checkins_idx01 ON schema_snow.checkins(fk_user_id);\n",
    "CREATE INDEX checkins_idx02 ON schema_snow.checkins(fk_gym_id);\n",
    "\n",
    "CREATE INDEX subscription_plans_idx01 ON schema_snow.users(fk_subscription_plan_id);\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
